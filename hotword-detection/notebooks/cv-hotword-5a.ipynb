{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>**Response to Task 5(a)**</u>\n",
    "1. Assume that hotword detection is asking to detect the **intended** words the speaker uttered (though he/she may have uttered with an accent / make a mistake vocalizing it, OR there was an transcription mistake).\n",
    "1. Therefore, being able to tolerate errors in the transcript is paramount.\n",
    "1. Without going into complex manual post-ASR correction techniques (e.g. passing into yet another Language Model to 'correct' the transcription, or estimating phoneme from grapheme), my proposal uses Fuzzy RegEx as a quick and dirty way to detect such hotwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_DIR = Path.home() / \"work/htx-xdata\"  # TODO change this to the path of your repo\n",
    "TASK_DIR = PROJECT_DIR / \"asr-train\"\n",
    "src_dir = TASK_DIR / \"src\"\n",
    "\n",
    "\n",
    "if src_dir.as_posix() not in sys.path:\n",
    "    sys.path.insert(0, src_dir.as_posix())\n",
    "# NOTE: You may also want to add `\"python.analysis.extraPaths\": [\"./asr-train/src\"]` to your VSCode workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import regex as re\n",
    "from app.config import pth_hotwords_txt, pth_valid_dev_raw\n",
    "from utils_ds import get_df_valid_dev\n",
    "\n",
    "pd.options.display.max_colwidth = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pattern with up to 1 edits (insertions, deletions, or substitutions)\n",
    "RGX_hotword_w_1edits = re.compile(r\"\\b(?:BE CAREFUL|DESTROY|STRANGER){e<=1}\\b\", re.IGNORECASE)\n",
    "# NOTE: Assume we are NOT interested in past tense e.g. 'was careful', 'destroyed'.\n",
    "\n",
    "# Known false positives\n",
    "KNOWN_BLACKLIST = {\"STRANGE\", \"STRONGER\"}\n",
    "\n",
    "\n",
    "def detect_hotwords_fuzzy(txt: str) -> re.Match:\n",
    "    \"\"\"Detect hotwords in the text `txt` using fuzzy matching with up to 1 edits.\"\"\"\n",
    "    # TODO For cases where the hotword is very short (e.g. \"NO\"), we may want to use pure exact match instead.\n",
    "    # In our case, the shortest hotword is \"DESTROY\". 1 edits out of 7 characters is still roughly acceptable (~14%),\n",
    "    # but expect some false positives and corner cases... May need to maintain blacklist of false positives.\n",
    "    return RGX_hotword_w_1edits.search(txt)\n",
    "\n",
    "\n",
    "def postprocess_fuzzy(mtc: re.Match) -> str:\n",
    "    \"\"\"Postprocess the transcribed text `txt` to correct common errors.\"\"\"\n",
    "    if mtc:\n",
    "        txt = mtc.group()\n",
    "        if txt.strip().upper() in KNOWN_BLACKLIST:\n",
    "            return None\n",
    "        return txt\n",
    "    return None\n",
    "\n",
    "\n",
    "def test_detect_hotwords_fuzzy():\n",
    "    \"\"\"Unit test...\"\"\"\n",
    "    txt_n_should_match_tpls = [\n",
    "        (\"You must be carful\", True),  # Misspelled \"be careful\" 1 edit\n",
    "        (\"You mustbe carful\", False),  # Misspelled \"be careful\" but partial-word match\n",
    "        (\"You must be carful\", True),  # Misspelled \"be careful\" 1 edits\n",
    "        (\"destroyy\", True),  # Extra character\n",
    "        (\"strangr\", True),  # Missing 'e'\n",
    "        (\"You must be careful of the Dark.\", True),  # Exact match\n",
    "        (\"random text\", False),\n",
    "    ]\n",
    "\n",
    "    for txt, should_match in txt_n_should_match_tpls:\n",
    "        mtc = RGX_hotword_w_1edits.search(txt)\n",
    "        if mtc:\n",
    "            if should_match:\n",
    "                continue\n",
    "            print(f\"[failed case;YES]: '{txt}': '{mtc.group()}'\")\n",
    "        else:\n",
    "            if not should_match:\n",
    "                continue\n",
    "            print(f\"[failed case;NO] : '{txt}'\")\n",
    "            # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev = get_df_valid_dev(pth_valid_dev_raw)\n",
    "# case where clip is totally silent -> no transcription\n",
    "df_dev.fillna({\"generated_text_finetuned\": \"\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev[\"mtc\"] = df_dev[\"generated_text_finetuned\"].apply(detect_hotwords_fuzzy)\n",
    "df_dev[\"hotword\"] = df_dev[\"mtc\"].apply(postprocess_fuzzy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## [EDA] Regex matches\n",
    "# df_debug = df_dev.dropna(subset=['mtc'])\n",
    "# df_debug = df_debug[['filename', 'text', 'generated_text_finetuned', 'mtc', 'stats']]\n",
    "# df_debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## [EDA] hotwords\n",
    "# df_debug = df_dev.dropna(subset=['hotword'])\n",
    "# df_debug = df_debug[['filename', 'text', 'generated_text_finetuned', 'mtc', 'hotword', 'stats']]\n",
    "# df_debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write\n",
    "df_dev.query(\"hotword.notna()\")[\"filename\"].to_csv(pth_hotwords_txt, index=False, header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "htx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
