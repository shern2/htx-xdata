{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>**Response to Task 5(b)**</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_DIR = Path.home() / \"work/htx-xdata\"  # TODO change this to the path of your repo\n",
    "TASK_DIR = PROJECT_DIR / \"asr-train\"\n",
    "src_dir = TASK_DIR / \"src\"\n",
    "\n",
    "if src_dir.as_posix() not in sys.path:\n",
    "    sys.path.insert(0, src_dir.as_posix())\n",
    "# NOTE: You may also want to add `\"python.analysis.extraPaths\": [\"./asr-train/src\"]` to your VSCode workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from app.config import pth_valid_dev_raw\n",
    "from InstructorEmbedding import INSTRUCTOR\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from utils_ds import get_df_valid_dev\n",
    "\n",
    "pd.options.display.max_colwidth = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = INSTRUCTOR(\"hkunlp/instructor-large\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev = get_df_valid_dev()\n",
    "df_dev.dropna(subset=[\"generated_text_finetuned\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction_qry = \"Represent the Speech Transcript sentence:\"\n",
    "instruction_doc = \"Represent the Speech Transcript sentence for retrieval:\"\n",
    "\n",
    "# instruction_qry = \"Represent the sentence for retrieving supporting speech transcripts:\"\n",
    "# instruction_doc = \"Represent the speech transcript for retrieval:\"\n",
    "# instruction_qry = \"Represent the Safety sentence for retrieving supporting speech transcripts:\"\n",
    "# instruction_doc = \"Represent the Safety speech transcript for retrieval:\"\n",
    "# instruction_qry = \"Represent the Safety sentence for retrieving supporting speech transcripts with cautionary, destructive, or suspicious meanings:\"\n",
    "# instruction_doc = \"Represent the Safety speech transcript for retrieval with cautionary, destructive, or suspicious meanings:\"\n",
    "# instruction_qry = \"Represent the Safety question for retrieving speech transcripts with cautionary, destructive, or suspicious meanings (accounting for transcription errors):\"\n",
    "# instruction_doc = \"Represent the Safety speech transcript for retrieval with cautionary, destructive, or suspicious meanings (accounting for transcription errors):\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = [\n",
    "    [instruction_qry, qry]\n",
    "    for qry in [\n",
    "        \"Take caution\",  # BE CAREFUL\n",
    "        \"Seek to destroy\",  # DESTROY\n",
    "        \"Stranger is present\",  # STRANGER\n",
    "    ]\n",
    "]\n",
    "query_embeddings = model.encode(query)\n",
    "\n",
    "corpus = [[instruction_doc, transcript.lower()] for transcript in df_dev[\"generated_text_finetuned\"]]\n",
    "corpus_embeddings = model.encode(corpus)\n",
    "\n",
    "similarities = cosine_similarity(query_embeddings, corpus_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## [EDA] tuning the threshold (and the instructions)\n",
    "hotword_to_threshold = {\n",
    "    \"BE CAREFUL\": 0.83,\n",
    "    \"DESTROY\": 0.83,\n",
    "    \"STRANGER\": 0.85,\n",
    "}\n",
    "\n",
    "df_detecteds = []\n",
    "\n",
    "DEBUG = False\n",
    "# DEBUG = True # TODO disable\n",
    "TGT_QRY_IDX = 0\n",
    "for qry_idx, (hotword, threshold) in enumerate(hotword_to_threshold.items()):\n",
    "    if DEBUG and qry_idx != TGT_QRY_IDX:\n",
    "        continue\n",
    "\n",
    "    scores = similarities[qry_idx]\n",
    "    sorted_indices = np.argsort(scores)  # Sort scores ascending\n",
    "    sorted_scores = scores[sorted_indices]\n",
    "    sorted_docs = df_dev.iloc[sorted_indices]  # Sort DataFrame rows accordingly\n",
    "\n",
    "    # Find the closest index where scores cross the threshold\n",
    "    above_idx = np.searchsorted(sorted_scores, threshold, side=\"left\")\n",
    "\n",
    "    # Get 3 documents before and after the threshold\n",
    "    start_idx = max(0, above_idx - 3)\n",
    "    end_idx = min(len(sorted_scores), above_idx + 3)\n",
    "\n",
    "    # Note down the detected documents\n",
    "    df_detected = df_dev.iloc[sorted_indices[above_idx:]].assign(score=sorted_scores[above_idx:])\n",
    "    df_detecteds.append(df_detected)\n",
    "\n",
    "    if DEBUG and qry_idx == TGT_QRY_IDX:\n",
    "        break\n",
    "\n",
    "\n",
    "df_debug = df_dev.assign(score=scores)\n",
    "display(df_debug.iloc[sorted_indices[start_idx:end_idx]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # [debug]\n",
    "# filenames = [\"cv-valid-dev/sample-001791.mp3\", \"cv-valid-dev/sample-001440.mp3\"]\n",
    "# df_debug.query(f\"filename in @filenames\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # [debug]\n",
    "# for hotword, df_detected in zip(hotword_to_threshold, df_detecteds):\n",
    "#     print(f\"Detected {hotword}:\")\n",
    "#     display(df_detected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = pd.concat([df_detected[[\"filename\"]] for df_detected in df_detecteds])[\"filename\"].unique()\n",
    "df_dev_out = df_dev.drop(columns=[\"stats\"]).assign(similarity=lambda df: df[\"filename\"].isin(filenames))\n",
    "df_orig = pd.read_csv(pth_valid_dev_raw.with_suffix(\".csv.bak\"))\n",
    "df_dev_out = df_orig.merge(\n",
    "    df_dev_out[[\"filename\", \"generated_text\", \"generated_text_finetuned\", \"label\", \"similarity\"]],\n",
    "    how=\"left\",\n",
    "    on=\"filename\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write\n",
    "df_dev_out.to_csv(pth_valid_dev_raw, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "htx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
